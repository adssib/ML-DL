{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# COMP 433: Deep Learning, Lab 3"],"metadata":{"id":"w-50P9uyWQMf"}},{"cell_type":"markdown","metadata":{"id":"S02d9PimAZKJ"},"source":["In this lab we will learn some basics of PyTorch. Save your answers for this lab as they will be used for part of Lab 3.\n","\n"]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, transforms"],"metadata":{"id":"xbvPG18fXg0c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading Datasets in PyTorch"],"metadata":{"id":"Eoy2Bit8WXzC"}},{"cell_type":"markdown","metadata":{"id":"CIDPxv5l2qpI"},"source":["### Exercise 1\n","\n","> Below, we create a _dataloader_ for the **MNIST** training data using the `torchvision` package (following e.g. https://github.com/pytorch/examples/blob/master/mnist/main.py#L112-L120).\n","\n","> The dataloader iterates over the training set outputing mini-batches of size 256 image samples. Note you do not need to use the image labels in the rest of this lab.\n","\n","> The `device` variable allows us to select which device to place the data on.\n","\n","- Modify your colab (or local environment) to use a GPU and then set `device=\"cuda\"` by rerunning the cell below such that the data is placed on GPU inside the for loop.\n"]},{"cell_type":"code","source":["dataset1 = datasets.MNIST('../data', train=True, download=True,\n","                          transform=transforms.ToTensor())\n","train_loader = torch.utils.data.DataLoader(dataset1,\n","                                           batch_size=256,\n","                                           shuffle=True,\n","                                           drop_last=True)\n","\n","device = 'cuda'\n","\n","for (data, target) in train_loader:\n","    data = data.to(device)\n","    target = target.to(device)\n","\n","print(data.shape)\n","print(target.shape)"],"metadata":{"id":"QfDg7vxJbGRe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0a82b88-be60-4a4f-aa7a-486715e19c10","executionInfo":{"status":"ok","timestamp":1695603321541,"user_tz":240,"elapsed":15084,"user":{"displayName":"marc eid","userId":"05620383249117050730"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 1, 28, 28])\n","torch.Size([256])\n"]}]},{"cell_type":"markdown","source":["- Find 1 example per each digit (10 images) and plot them using `plt.imshow`.\n","    - All 256 images are **randomly** stacked over the `data` tensor; as indicated by the tensor's first dimension.\n","    - _Remember that the labels can be found in the `target` tensor`_\n","    - Use indexing (as you learned on previous labs) to select any particular image.\n","    - Once selected, use `torch.view` to make sure your slice has `[28,28]` shape.\n","    - `plt.imshow` will throw a `TypeError` if the passed object does not reside on CPU. Use the [`.cpu`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html) function to bring your tensors back to CPU before plotting.\n","        - **HINT**: This should only require 1 line of code.\n","    - For clarity, you may want to specify a gray color map to `matplotlib` (i.e. pass `cmap='gray'` as argument to `plt.imshow`).\n","\n","> NOTE: The [`.detach`](https://pytorch.org/docs/stable/generated/torch.Tensor.detach.html) function often preceeds `.cpu` as we might be in situation where we want to work with a particular part of one's computation graph. Thus, it's a good practice to create a copy of it apart, so that the original computation graph doesn't get affected."],"metadata":{"id":"54xWTkv5dGrG"}},{"cell_type":"code","source":["# your code goes here\n"],"metadata":{"id":"PNZXOtsJccVa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch Primitives"],"metadata":{"id":"MQJ42Zr3WhSV"}},{"cell_type":"markdown","metadata":{"id":"14MBuiusdZmA"},"source":["### Exercise 2\n","\n","- Using only torch primitives (e.g. [torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html), [torch._relu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), etc) implement a _simple feedforward neural network_ with 2 _hidden layers_ that takes as input MNIST digits (28x28) and outputs **a single scalar value**.\n","    - You may select the _hidden layer width_ (greater than 20) and activations (`tanh`, `relu`, `sigmoid`, others) as desired.  Initialize the weights  with [uniform random values](https://pytorch.org/docs/stable/generated/torch.rand.html) in the range -1 to 1 and [biases at 0](https://pytorch.org/docs/stable/generated/torch.zeros.html).\n","    - Avoid using any functions from `torch.nn` class. Using the loop from Exercise 1, _forward pass_ through the dataset in _mini-batches of 256_.\n","- Perform a forward pass using `my_nn` function"]},{"cell_type":"code","metadata":{"id":"bhZ0I_q7dnb9"},"source":["import torch\n","\n","# Initialize and track the parameters using a list or dictionary\n","h1_size = 25\n","h2_size = 25\n","param_dict = {\n","    \"W0\": , #28*28 since image pixels are flattened\n","    \"b0\": , #10 classes\n","    #each output of h1 will be a vector of shape (10,)\n","    \"W1\": ,\n","    \"b1\": ,\n","\n","    \"W2\": ,\n","    \"b2\": ,\n","    }\n","\n","for name, param in param_dict.items():\n","  param_dict[name] = param.to(device)\n","  param.requires_grad=True\n","\n","# Define the network\n","def my_nn(input, param_dict):\n","    r\"\"\"Performs a single forward pass of a Neural Network with the given\n","    parameters in param_dict.\n","\n","    Args:\n","        input (torch.tensor): Batch of images of shape (B, H, W), where B is\n","            the number of input samples,and H and W are the image height and\n","            width respectively.\n","        param_dict (dict of torch.tensor): Dictionary containing the parameters\n","            of the neural network. Expects dictionary keys to be of format\n","            \"W#\" and \"b#\" where # is the layer number.\n","\n","    Returns:\n","        torch.tensor: Neural network output of shape (B, )\n","    \"\"\"\n","\n","    # input\n","\n","\n","    # layer 1\n","\n","\n","    # layer 2\n","\n","\n","    # output\n","\n","\n","    return\n","\n","\n","# Perform forward pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch Neural Modules"],"metadata":{"id":"ffZfi07tbgas"}},{"cell_type":"markdown","metadata":{"id":"ndXpk3C5bwQ8"},"source":["### Exercise 3\n","\n","- Implement a new `torch.nn.module` that performs the equivalent of the network in Exercise 2 and call it `\"model\"`.\n","- Initialize it with the same weights\n","    - for instance: `nn.Linear(in_features, out_features).weight.data = insert your desired weights`;\n","    - you could do a similar thing (as above) with the bias.\n","- Validate that the outputs of this network are the same as the one in Exercise 2 on the MNIST training set."]},{"cell_type":"code","metadata":{"id":"Nbgzjuqtlhvx"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Model(nn.Module):\n","    def __init__(self, h1_siz, h2_siz):\n","        super(Model, self).__init__()\n","        self.linear1 =\n","        self.linear2 =\n","        self.linear3 =\n","\n","    def forward(self, x):\n","\n","        return\n","\n","# Make an instance of Model here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Validating the implementations match.\n","    - First you will need to make sure the `param_dict` from Exercise 2 and the nn module version have the same parameters.\n","    - You can do this for example using:\n","`model.linear1.weight.data = copy.deepcopy(param_dict['W0'].data.T)`\n","\n","**Hint:** To make sure that the outputs are roughly equal find the mean of the squared difference between the output of the PyTorch modedl and the output of your nn function squared. This value should be less than 1e-4."],"metadata":{"id":"KLgkHOa6TnsJ"}},{"cell_type":"code","source":["import copy\n","\n","# We can access all the variables in model and manipulate them directly\n","\n","# Note here we do a deepcopy just to make sure this model is separate from the one in the above cell\n","\n","for i,(data, _) in enumerate(train_loader):\n","  data = data.to(device)\n","  # check that all the outputs are roughly equal\n","print(\"All Clear !\")"],"metadata":{"id":"-2j98UsXTqza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For completeness this cell is helpful if you are reruning the answers and thus need to clear the previous gradient\n","# There is a need to clear the gradient buffers before computing the backward pass\n","model.zero_grad() # for nn module\n","\n","for (_,param) in param_dict.items():\n","  if param.grad is not None: # grad buffer doesnt exist until the first backward pass\n","    param.grad.detach_() # by default the gradient is in the computation graph\n","    param.grad.zero_()"],"metadata":{"id":"LVhZUiHbjGUe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 4"],"metadata":{"id":"VTk7DHZX0YNB"}},{"cell_type":"markdown","source":["In this exercise, we will take a closer look at how neural networks perform without training and why training is essential for their success."],"metadata":{"id":"1VCl_ytl0hW4"}},{"cell_type":"markdown","source":["1- Use your untrained \"model\" network that contains random initial weights and biases.\n","\n","2- Input a single data point (MNIST image) into the model and observe the prediction it generates. Compare this prediction with the label of the image."],"metadata":{"id":"NQKHZZLt05mR"}},{"cell_type":"code","source":[],"metadata":{"id":"7Kf0cheh0g1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Summarize your observations"],"metadata":{"id":"OyINQz261MBq"}},{"cell_type":"markdown","source":["## Learning about computational graphs"],"metadata":{"id":"w1TLXx_2e9dl"}},{"cell_type":"markdown","source":["In this exercise, you will use your pytorch model to visualize its computational graph. You'll gain insights into how neural networks compute and propagate gradients.\n","\n","First run the cell below to import torchviz for visualization of the computational graph.\n"],"metadata":{"id":"hu0bMNVDpT32"}},{"cell_type":"code","source":["pip install torchviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6kIHclCff0U","executionInfo":{"status":"ok","timestamp":1695317226128,"user_tz":240,"elapsed":3938,"user":{"displayName":"Nada Abdel Khalek","userId":"11697401212249847314"}},"outputId":"0b86ee7a-8997-4690-a625-f16afe5e1fe0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"]}]},{"cell_type":"markdown","source":["Computational Graph Legend:\n","\n","- **Blue Boxes:** Leaf nodes, often representing tensors or variables, including input data, weights, and biases.\n","\n","- **Grey Boxes:** Intermediate operations in the graph, such as activations, backward pass operations, or other computations during forward and backward passes."],"metadata":{"id":"BMvTCnYqpJIu"}},{"cell_type":"code","source":["import torchviz\n","# Input data into your PyTorch model and store the output in a variable\n","output =\n","\n","# Create the computational graph with custom node names\n","graph = torchviz.make_dot(output, params=dict(model.named_parameters()))\n","\n","# Display the graph with variable names\n","display(graph)"],"metadata":{"id":"428f9nZse8kc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 4"],"metadata":{"id":"zf08Fcq7qr5Z"}},{"cell_type":"markdown","source":["Using the generate computational graph, identify and label the following components:\n","\n","- Input data.\n","- Weight and bias tensors.\n","- Activation functions (ReLU).\n","- Linear transformations (matrix multiplications).\n","\n","Describe the flow of data from input to output.\n","Explain how gradients are computed during the backward pass for weight updates."],"metadata":{"id":"mGJVpE50p6MX"}},{"cell_type":"markdown","source":["Your answer:"],"metadata":{"id":"QeDtS8AeqeJZ"}},{"cell_type":"markdown","source":["## Training Models in PyTorch"],"metadata":{"id":"USN17pAjbokW"}},{"cell_type":"markdown","metadata":{"id":"t4WyZ8PFFuMT"},"source":["### Exercise 5\n","\n","- For a single mini-batch of 256 samples (you can select any mini-batch), compute the gradient of the average of the neural network outputs (over the batch) w.r.t. to the weights using `torch.autograd`.\n","- Print the gradients for the first layer weights and biases.\n","    - You can use either the model defined from Exercises 2 or 3 for this.  \n","\n","**Note**: The network here is\n","$$\n","f: \\mathcal{R}^{HW}\\rightarrow\\mathcal{R},\n","$$\n","with $256$ samples. You should obtain\n","\n","$$\n","o=\\frac{1}{256}\\sum_{i=0}^{255}f(x_i)\n","$$\n"]},{"cell_type":"code","metadata":{"id":"_WoNwefYGPWL"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-YHbWOIQHKow"},"source":["### Exercise 6\n","\n","> Below you will find code for comparing the speed of a model on CPU and GPU as well as comparing the speed of a forward pass to a forward/backward pass.\n","\n","- Instantiate a version of your model from Exercise 3 (preferably a larger version e.g. width 100 or 500) and run the timing code.\n","- Write 1-2 sentences to summarize your observations about the relative speed's of CPU/GPU and forward/backward."]},{"cell_type":"code","source":["#Instantiate a model defined from (3) here\n","model ="],"metadata":{"id":"jIP99BLcd6mQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Run on CPU\n","import time as timer\n","data = data.to('cpu')\n","model.cpu()\n","\n","print('Running on CPU')\n","\n","start = timer.time()\n","for _ in range(10):\n","    model(data)\n","print(\"Time taken forward\", timer.time() - start)\n","\n","start = timer.time()\n","for _ in range(10):\n","    out = model(data).mean()\n","    out.backward()\n","print(\"Time taken forward/backward\", timer.time() - start)"],"metadata":{"id":"U_YXGlTaeC_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Run on GPU\n","#initialize cuda\n","data = data.to('cuda')\n","model.cuda()\n","model(data)\n","print('Running on GPU')\n","\n","\n","start = timer.time()\n","for _ in range(10):\n","    model(data)\n","torch.cuda.synchronize()\n","print(\"Time taken\", timer.time() - start)\n","\n","start = timer.time()\n","for _ in range(10):\n","    out = model(data).mean()\n","    out.backward()\n","torch.cuda.synchronize()\n","print(\"Time taken forward/backward\", timer.time() - start)"],"metadata":{"id":"KNTKRXeWePzl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Summary of observations here:"],"metadata":{"id":"1oLuAwYyeqqt"}}]}